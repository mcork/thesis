\section{Chapter 2: Literature Review}The literature for this thesis has been split up into four sections. They are Inter-process communication, Bandwidth Estimation, Routing Protocols and OG sharing.\newlineComputer systems are machines that constantly have interprocessing communication\cite{FordHamacher}. Ford and Hamacher\cite{FordHamacher} discussed a hardware implementation for increased efficiency. They proved that this was benefial however it would required a redesign of the hardware to support it.\newlineGraham explored the use of \textquotedblleft BINS\textquotedblright  to implement inter process communication. Their approach consisted of a set of structures that are inherited by the parent program. The bin had two functions \textquoteleft PLACE\textquoteright  and \textquoteleft TAKE\textquoteright  that are used by the programs to publish their data. \newlineThe main disadvantage of this approach is programs need to be spawned by the same parent to have access the same data. Another disadvantages are the programs are unable to easily select the message they want and the BINS can only store data structures that are programmed for (int, string).One of the most common IPC with built in data corruption protection is the use of a circular buffer. The circular buffer idea to avoid corruption is a common solution for device drivers \cite{circularBuffer}. This is often used as it can allow for multiple readers to read one person's data without the chance of corruption happening. The main advantage of this approach is it has been proven to be effective and corruption free way to share data between one writer and multiple readers. The major disadvantage of this approach is that it hasn’t been tested for multiple readers and multiple writers\newlineSumathi and Thanamani\cite{SumanthiThanamani} discuss an approach for collision avoidance and bandwidth estimation for intelligent sending protocols. They proved the Implicit pipeline backoff method reduced the quantity of data sent while also increasing the throughput of the wireless nodes. It was designed for multiple hop networks, so it handles efficiently the communication. The main disadvantage of this approach is it is written on the link layer and also would need to have unique identifiers added to distinguish between each platform as currently the MAC protocol on the link layer or the IP protocol on the Network layer handles this.Differing Routing algorithms have been research to try and determine the most efficient protocol to implement. The major disadvantage with these approach is they are all written on the link layer. Although this makes them unable to be used the research if able to be used on the application layer for my protocols.\newline Pham Van's\cite{Van} researched the issues of bandwidth-hogging and time-sensitivity that is required when streaming video (high volume data) over an adhoc network by proposing a new proactive architecture. The paper analyses the re-transmission time and explains how the new architecture handles the incoming packets. The procedure for handling the incoming packets includes checking if the round trip time  is less than a set threshold of delay. The protocol discards the packet if it is above the threshold or sends it on if it isn\textquoteright t. A discarded packet means that there is a faster path within the structure. The packets that have less delay are selected for retransmission to the next node in the sequence. The loss of packets is handles by an NACK which reduces the quantity of ACK messages on the bandwidth.\newlineThe paper presents an architecture that allows the efficient streaming of video in real time. The strength of this approach is that the data is sent over the quickest path and and thus doesn't flood the network. The major disadvantage is, as all nodes know if they are part of the quickest route if the structure changes suddenly their is no redundancy for this data and the data is lost. In a Dynamic MANET the structure is constantly changing and thus packets don’t know the fastest path or if the node actually exists.\newlinePutta, Prasad, Ravilla, Nath and Chandra \cite{PuttaEtAl} outlined the different algorithms used for routing in Mobile Adhoc Networks (MANETS). The paper cover two different reactive algorithms; Adhoc on Demand Distance Vector (AODV) and Dynamic Source Routing (DSR), and the main proactive protocol Optimised Link State Routing (OLSR). These algorithms were compared based on the following criteria; Packet Delivery Ratio, Mean end-to-end delay and Routing load. Neither reactive protocol proved to be the superior than the other. \newlineThe paper shows that if the OG was high bandwidth load it would be more efficient and reliable to use a proactive protocol however for low load data (such as control signals) the reactive protocol would be the better choice. The tests of these protocols however didn't allow for a drastically changing MANET.\newlineLee, Ra and Kim \cite{LeeRaKim} investigated three other methods of routing; DSR and AODV with Gossiping and AODV with flooding. Gossiping is the process of the node determining whether to resend based on a fixed probability function.\newlineIt was shown that DSR was only effective for small networks. Whereas AODV with flooding was proven to reduce the end to end delay of the packets however has a high routing overhead and increase the load on the bandwidth. The AODV + Gossip was shown to be an effective method, however more research is needed to increase the throughput as it currently has low probability of success.\newlineAbdel-Hardy and Ward \cite{HadyWard} also tested the difference between the proactive protocol (OLSR) and the reactive protocols; AODV and Dynamic Manet On Demand (DYMO). Their tests included one video stream with five UDP data connections, one video stream with 50 UDP connections and multiple video streams. \newlineThe tested the theory that the current protocols are acceptable for low latency applications, but they fail in situations with high latency applications and resulted in large packet loss. Their results showed that DYMO was the best protocol for small\/medium manets and for large and heavy use manets. AODV was the best for large and light use manets. OLSR was proven not to be suitable for the high latency communication.\newlineOG sharing over adhoc networks can be done using the above protocols and methods. Some research has already gone into trying to share OG over multiple platforms to create a “Network” OG. A network OG is a OG that is shared across all platforms and each platform updates its own copy then syncs with the other platforms. There are many different ways of representating OG’s and  many different ways to share them.\newlinePfingsthorn and Birk \cite{PfingsthornBirk} researched into the efficiency of sharing of the Occupancy Grid (OG) through the three following methods; Sending the occupancy grid periodically, sending the cells when they are alter or sending the sensor data used to create the OG.Their research showed that the most efficient method minimise bandwidth hogging was the sending the data set used to create the platform’s OG.  Each node used the same data sets that are sent across the network to generate its own OG map onboard. This method proved to be almost seven times faster than sending the cells as they are modified and over seventy times faster than sending the sections periodically.\newlineThe major disadvantage of this method is that all hosts need to have the same data set to have the same occupancy grid. In a dynamic structure used in manets the entire data set (from the beginning of the map) would need to be sent to ensure everyone has the same map. Failure to send the whole data would cause the platform to have a different data set and would generate a different map. The MAV wouldn’t be able to explore out of the network then upload the changes when it got back in range. This wouldn’t allow for distributed exploration. A possible solution to this problem could be the data sets get sent but the platforms also had an ability to sync the entire map less frequently.Jang, Choi and Lee\cite{JangChoiLee} explore creating the OG mapping implementation as a cluster of smaller cells. They showed that this approach allowed optimisation to be performed to increase the efficiency of all manipulations of the clusters. It also showed that the cluster were able to manipulated quicker than manipulating the same number of individual cells. Each cluster was made to be independent of the cells around it which would simplify the sending process through the network manager as the sections would already be made for you. The timing would be similar to Pfingsthorn and Birk second testing of changing the alter cells\cite{PfingsthornBirk}.